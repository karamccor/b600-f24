---
title: "Lecture 7: Continuous distributions"
subtitle: "BIOS 600 - Fall 2024"
author: "Kara McCormack"
logo: "images/logo_600.png"
format: 
  revealjs: 
    theme: slides.scss
    multiplex: true
    transition: fade
    slide-number: true
editor: visual
execute:
  freeze: auto
from: markdown+emoji
---

## Supplemental Reading

These readings are optional. All material in homework and exams will be covered in lecture and lab, and books do not cover everything we do in lecture (even if there is a corresponding section). 

However, for those with the very optional textbooks, the following sections correspond to today's lecture:

- Pagano and Gavreau: Section 7.4
- [OpenIntro Statistics](https://www.openintro.org/go/?id=os4_for_screen_readers&referrer=/book/os/index.php): 3.5, 4.1

## Review: Discrete probability distributions {.smaller}

::: columns
::: {.column width="50%"}

There are three rules for discrete probability distributions:

- Outcomes must be disjoint
- The probability of each outcome must be $\geq$ 0 and $\leq$ 1
- The sum of the outcome probabilities must add up to 1 

:::
:::{.column width="50%"}

| Event            | Probability  |
|------------------|--------------|
| *X = pre*        | 0.10         |
| *X = early*      | 0.27         |
| *X = full*       | 0.57         |
| *X = late/post*  | 0.06         |


:::

:::

## Review: Expectation and variance

- The expectation is the average value (weighted by the probability of each value occurring)

- The variance describes the expected spread of values around the population expectation (thus, variance is in fact an expectation itself!)

## Can we be more precise? {.smaller}

Letting $X$ be the random variable that corresponds to how long a baby's gestation was, we could imagein subdividing further and further:

::: columns
::: {.column width="50%"}

| Event            | Probability  |
|------------------|--------------|
| $X$ < 20 wk.        | $P(X < 20)$        |
| $X$ = 20 to 21 wk.      | etc.         |
| $X$ = 21 to 22 wk.      | etc.         |
| $X$ = 22 to 23 wk.      | etc.         |
| $\vdots$    | $\vdots$         |

:::
:::{.column width="50%"}

| Event            | Probability  |
|------------------|--------------|
| $X$ < 20 wk.        | $P(X < 20)$        |
| $X$ = 20 to 20.1 wk.      | etc.         |
| $X$ = 20.1 to 20.2 wk.      | etc.         |
| $X$ = 20.2 to 20.3 wk.      | etc.         |
| $\vdots$    | $\vdots$         |

:::

:::

## Can we be more precise?

- Now let gestational age $X$ be a [continuous]{style="color: RosyBrown"} random variable, which can take on *any* value, say from 0 to $\infty$. 

- How might we define a continuous probability distribution that corresponds to $X$?

## continuous probability distributions

- The probability that a continuous variable equals any specific value is 0

- No use tabulating - there is an *uncountably* infinite number of possible values they can be, all with $P(X = x) = 0$

- The distribution is given by a [probability density function]{style="color: RosyBrown"}, helps us describe probabilities for *ranges* of values. 

## Density functions {.smaller}

Probability density functions may be given graphically, satisfying the following two rules:

- The density must be non-negative everywhere $(f(x) \geq 0$ for all $x$ from $-\infty$ to $\infty$)

- The total area under the density must be 1



```{r}
#| fig-height: 3
#| fig-width: 8

# Set up the plotting area to have 1 row and 3 columns
par(mfrow = c(1, 3))

# Set up the x-axis values for the normal distribution
x_normal <- seq(-4, 4, length = 1000)
y_normal <- dnorm(x_normal, mean = 0, sd = 1)

# Plot the density of the standard normal distribution
plot(x_normal, y_normal, type = "l", lwd = 2, main = "Normal Distribution",
     xlab = "Value", ylab = "Density", col = "black")

# Set up the x-axis values for the uniform distribution
x_uniform <- seq(0, 1, length = 1000)
y_uniform <- dunif(x_uniform, min = 0, max = 1)

# Plot the density of the uniform distribution
plot(x_uniform, y_uniform, type = "l", lwd = 2, main = "Uniform Distribution",
     xlab = "Value", ylab = "Density", col = "black")

# Set up the x-axis values for the exponential distribution
x_exponential <- seq(0, 6, length = 1000)
y_exponential <- dexp(x_exponential, rate = 1)

# Plot the density of the exponential distribution
plot(x_exponential, y_exponential, type = "l", lwd = 2, main = "Exponential Distribution",
     xlab = "Value", ylab = "Density", col = "black")

# Reset plotting layout
par(mfrow = c(1, 1))

```


## Density functions {.smaller}

We can define events for continuous distributions and assign probabilities to them using density functions:

- Suppose $X$ follows some density function $f(x)$
- We are interested in the event "$X$ lies between $a$ and $b$"

- We calculate the following probability:

$$P(a < X < b) = \int_a^b f(x) dx$$

::: {.callout-caution appearance="simple"}

## Note

Computers do this for us these days; no need to worry about the expression above)
:::

## What would this look like graphically?

```{r}
#| fig-height: 5

# Set up the x-axis values
x <- seq(-4, 4, length = 1000)

# Compute the density of the standard normal distribution
y <- dnorm(x, mean = 0, sd = 1)

# Plot the standard normal distribution
plot(x, y, type = "l", lwd = 2, main = "Standard Normal Distribution",
     xlab = "Value", ylab = "Density")

# Shade the area above x = 2.5
x_shade <- seq(0.5, 1.5, length = 1000)
y_shade <- dnorm(x_shade, mean = 0, sd = 1)
polygon(c(0.5, x_shade, 1.5), c(0, y_shade, 0), col = "darkgoldenrod3", border = NA)

```


## The normal (Gaussian) distribution


::: columns
::: {.column width="70%"}

For the [normal distribution]{style="color: RosyBrown"}, 

$$f(x) = \frac{1}{\sqrt{2\pi \sigma^2}} \textrm{exp}\Bigl\{-\frac{1}{2} \frac{(x - \mu)^2}{\sigma^2}\Bigr\}$$

where $\mu$ is the mean and $\sigma^2$ is the variance.

- We often write $N(\mu, \sigma^2)$.

:::
:::{.column width="30%"}

![](images/lec-7/gauss.jpg)
:::

:::

## 68-95-99.7

![](images/lec-7/empirical.png)

## Standardization

- The normal distribution is a family of distributions of a specific form. There are an infinite amount of possible distributions, since $\mu$ can be any real number and $\sigma^2$ can be any positive number. 

- It would be very cumbersome to have to individually think about a $N(0, 20)$ vs. $N(2.5, 2)$ vs. $N(694, 1549)$ vs. .... distribution, depending on the situation. 

- In practice, we could calculate a [standard score]{style="color: RosyBrown"}  that gives the number of standard deviations away from the mean an observation from a particular population is. 



::: {.callout-caution appearance="simple"}

## Question

Why would we want to standardize?

:::

## z-scores {.smaller}

- A [z-score]{style="color: RosyBrown"} tells us how many population standard deviations an observation is away from the population mean.

- They provide ways to compare results across many different measurement scales, since z-scores are *unitless*

$$z=\frac{x-\mu}{\sigma}$$

(note the use of population parameters $\mu$ and $\sigma$)

- So, a z-score of 1.2 is 1.2 standard deviations above a mean; a z-score of 0.8 is 0.8 standard deviations below the mean.


## Osteoporosis {.smaller}

::: columns
::: {.column width="50%"}

![](images/lec-7/osteo.png)

:::
:::{.column width="50%"}

- According to NHANES, the mean bone minearl density for a 65 year old white woman is 809 mg/cm$^2$, with a standard deviation of 140 mg/cm$^2$. 

- Suppose you are a 65 year old white woman whose bone density is 698 mg/cm$^2$. Should you be very concerned about osteoporosis?
:::
:::